{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjHu99s_3f73"
      },
      "source": [
        "**RAG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mtU7ZQ-XOz2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce7708bd-72f1-460e-e594-d2572c1247f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.68.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.16.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.16.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53770 sha256=9b1b6b031f02ebb7ef058245565dc5b1188224b8dc341ed9604273d750ec1c8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.16.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "57f8f3ecb2dd4302b501f1fe7cb64e69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.8)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.45.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "^C\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install google-generativeai\n",
        "!pip install chromadb\n",
        "!pip install fastapi uvicorn pyngrok nest-asyncio\n",
        "!pip install flask flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "oduk7FGRmVU6",
        "outputId": "03652074-c3d0-45d4-d3ad-436544394891"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyngrok'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4fafcfb0aeed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 使用 ngrok 讓 Colab 對外公開\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyngrok'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from chromadb.config import Settings\n",
        "import chromadb\n",
        "from google.genai.types import EmbedContentConfig\n",
        "import uuid\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# 使用 ngrok 讓 Colab 對外公開\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 初始化 FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "# Set up ChromaDB for vector storage\n",
        "def setup_chroma_db(path: str):\n",
        "    client = chromadb.PersistentClient(path=path)\n",
        "    return client\n",
        "\n",
        "chroma_db_path = \"/content/chroma_db\"\n",
        "chroma_client = setup_chroma_db(chroma_db_path)\n",
        "\n",
        "\n",
        "# Google API Key setup\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Load text file from Google Colab environment\n",
        "def load_text_file(file_path):\n",
        "    \"\"\"Loads text from a file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the text file in Google Colab.\n",
        "\n",
        "    Returns:\n",
        "        str: Text content of the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding='utf-8') as f:  # Added encoding for robustness\n",
        "            text_content = f.read()\n",
        "        return text_content\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "    except Exception as e: #Catch other exceptions\n",
        "        print(f\"An error occurred while loading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Split text into chunks for embedding\n",
        "def chunk_text(text, chunk_size=700, chunk_overlap=50):\n",
        "    \"\"\"Splits text into smaller chunks.\n",
        "\n",
        "    Args:\n",
        "        text: The input text string.\n",
        "        chunk_size: Maximum size of each chunk.\n",
        "        chunk_overlap: Number of overlapping characters between chunks.\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start_index = 0\n",
        "    if not isinstance(text, str):\n",
        "        print(\"Error: Input text must be a string.\")\n",
        "        return []\n",
        "    text_length = len(text)\n",
        "\n",
        "    while start_index < text_length:\n",
        "        end_index = min(start_index + chunk_size, text_length)\n",
        "        chunk = text[start_index:end_index]\n",
        "        chunks.append(chunk)\n",
        "        # Corrected start_index calculation for proper overlap\n",
        "        start_index += chunk_size - chunk_overlap\n",
        "        if chunk_size - chunk_overlap <= 0: #Prevents infinite loops\n",
        "            print(\"Warning: chunk_size <= chunk_overlap.  Setting chunk_overlap = 0\")\n",
        "            start_index = end_index\n",
        "            chunk_overlap = 0\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Embed text chunks using Gemini API\n",
        "def embed_text_with_gemini(text_chunks, model_name=\"models/embedding-001\"):\n",
        "    try:\n",
        "        if not text_chunks:  # Check if the list is empty\n",
        "            print(\"Warning: No text chunks to embed.\")\n",
        "            return []\n",
        "\n",
        "        embeddings = genai.embed_content(\n",
        "            model = model_name,\n",
        "            content=text_chunks,\n",
        "            task_type=\"retrieval_document\",\n",
        "            title=\"Text Chunks\"\n",
        "        )\n",
        "        print (f\"embeddings = {embeddings}\")\n",
        "        return embeddings['embedding']  # Corrected return value\n",
        "    except Exception as e:\n",
        "        print(f\"Error during embedding: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Add embeddings and text chunks to ChromaDB\n",
        "def add_to_chroma_db_with_metadata(client, embeddings, text_chunks, collection_name=\"rag_collection\"):\n",
        "    \"\"\"Adds embeddings and text chunks and metadata to ChromaDB.\n",
        "\n",
        "    Args:\n",
        "        client: ChromaDB client.\n",
        "        embeddings: List of embeddings.\n",
        "        text_chunks: List of corresponding text chunks.\n",
        "        collection_name: Name of the ChromaDB collection.\n",
        "\n",
        "    Returns:\n",
        "        chromadb.Collection: ChromaDB collection.\n",
        "    \"\"\"\n",
        "    collection = client.get_or_create_collection(name=collection_name)\n",
        "    #ids = [str(i) for i in range(len(text_chunks))] # Generate unique IDs\n",
        "\n",
        "     # Check for empty embeddings or text_chunks\n",
        "    if not embeddings or not text_chunks:\n",
        "        print(\"Error: Empty embeddings or text chunks.  Cannot add to ChromaDB.\")\n",
        "        return collection  # Return the existing collection (possibly empty)\n",
        "\n",
        "    # Ensure IDs are unique using UUID\n",
        "    ids = [str(uuid.uuid4()) for _ in range(len(text_chunks))]\n",
        "\n",
        "    # Define metadata for each embedding (can be adjusted based on your use case)\n",
        "    metadata = [{\"document_name\": f\"Document {i + 1}\", \"chunk_index\": i} for i in range(len(text_chunks))]\n",
        "\n",
        "    #Handle mismatched lengths\n",
        "    if len(embeddings) != len(text_chunks):\n",
        "      print(\"Warning Mismatched lengths between embeddings and documents\")\n",
        "      min_length = min(len(embeddings), len(text_chunks))\n",
        "      embeddings = embeddings[:min_length]\n",
        "      text_chunks = text_chunks[:min_length]\n",
        "      ids = ids[:min_length]\n",
        "\n",
        "\n",
        "    collection.add(\n",
        "        embeddings=embeddings,\n",
        "        documents=text_chunks,\n",
        "        ids=ids,\n",
        "    )\n",
        "    return collection\n",
        "\n",
        "# Retrieve relevant chunks from ChromaDB based on query\n",
        "def retrieve_relevant_chunks_with_metadata(client, query, collection_name=\"rag_collection\", model_name=\"models/embedding-001\", n_results=3):\n",
        "    \"\"\"Retrieves relevant text chunks from ChromaDB based on a query.\n",
        "\n",
        "    Args:\n",
        "        client: ChromaDB client.\n",
        "        query: User query string.\n",
        "        collection_name: Name of the ChromaDB collection.\n",
        "        model_name: Gemini embedding model to use for query.\n",
        "        n_results: Number of relevant chunks to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: List of retrieved text chunks.  Handles errors gracefully.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        collection = client.get_collection(name=collection_name)\n",
        "        query_embedding_response = embed_text_with_gemini([query], model_name=model_name)\n",
        "\n",
        "        #Check for failed query embedding\n",
        "        if not query_embedding_response:\n",
        "            print(\"Error: Could not embed the query.\")\n",
        "            return []\n",
        "\n",
        "        query_embedding = query_embedding_response[0]\n",
        "\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=n_results\n",
        "        )\n",
        "\n",
        "        # Extract relevant text chunks and metadata\n",
        "        relevant_documents = results['documents'][0]\n",
        "        metadata = []\n",
        "        content = []\n",
        "\n",
        "        # Return both documents and their metadata\n",
        "        for doc in relevant_documents:\n",
        "            # Split the document to separate metadata from the content\n",
        "            # Assuming the metadata is at the beginning of the document (e.g., 'File: <filename>')\n",
        "            file_info, content_info = doc.split(\"\\n\\n\", 1)  # Split by the first empty line\n",
        "            metadata.append(file_info)  # Metadata (e.g., file name)\n",
        "            content.append(content_info)  # Content (actual chunk text)\n",
        "            return content, metadata  # Return both content and metadata\n",
        "    except Exception as e:\n",
        "        print(f\"Error during retrieval: {e}\")\n",
        "        return [],[]  # Return empty lists on error\n",
        "\n",
        "\n",
        "# Generate response using Gemini API with retrieved context\n",
        "def generate_response_with_gemini(query, context_chunks, model_name=\"gemini-1.5-flash\"):\n",
        "    \"\"\"Generates a response using the Gemini API, incorporating context.\n",
        "\n",
        "    Args:\n",
        "        query: User query string.\n",
        "        context_chunks: List of relevant text chunks retrieved from ChromaDB.\n",
        "        model_name: Gemini model to use for response generation.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response.  Handles API errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        context = \"\\n\".join(context_chunks)\n",
        "        prompt_content = f\"\"\"Answer the query based on the context provided.\n",
        "\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Query:\n",
        "        {query}\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt_content)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during response generation: {e}\")\n",
        "        return \"An error occurred while generating the response.\"\n",
        "\n",
        "\n",
        "def store_embeddings_from_file(file_path):\n",
        "    \"\"\"Processes a file and stores its embeddings in ChromaDB with metadata included in documents.\"\"\"\n",
        "\n",
        "    # Step 1: Load text content from the file\n",
        "    text_content = load_text_file(file_path)\n",
        "    if not text_content:\n",
        "        return \"Error: Could not load the text file. Please check the file path.\"\n",
        "\n",
        "    # Step 2: Split text into chunks for embedding\n",
        "    text_chunks = chunk_text(text_content)\n",
        "    if not text_chunks:  # Handle the case where chunking fails\n",
        "        return \"Error: Could not chunk the text content.\"\n",
        "\n",
        "    # Step 3: Generate embeddings for the chunks\n",
        "    embeddings_response = embed_text_with_gemini(text_chunks)\n",
        "    if not embeddings_response:  # Handles case where embedding fails\n",
        "        return \"Error: Could not embed the text chunks.\"\n",
        "\n",
        "    # Step 4: Set up ChromaDB client and add embeddings with metadata\n",
        "    db_folder = \"chroma_db\"\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "    chroma_client = setup_chroma_db(db_path)\n",
        "\n",
        "    # Add embeddings and documents to ChromaDB, including metadata\n",
        "    documents_with_metadata = [\n",
        "        f\"File: {file_path}\\n\\nContent: {chunk}\" for chunk in text_chunks\n",
        "    ]\n",
        "\n",
        "    # Generate unique IDs for each document\n",
        "    ids = [str(uuid.uuid4()) for _ in range(len(text_chunks))]\n",
        "\n",
        "    # Add embeddings, documents, and ids to ChromaDB\n",
        "    chroma_collection = add_to_chroma_db_with_metadata(chroma_client, embeddings_response, documents_with_metadata, collection_name=\"rag_collection\")\n",
        "    return f\"Embeddings for {file_path} successfully stored in ChromaDB.\"\n",
        "\n",
        "\n",
        "def preform_rag_with_query(query):\n",
        "    \"\"\"Orchestrates the RAG process without specifying the data file\n",
        "\n",
        "    Args:\n",
        "        query: User query string.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response based on RAG.\n",
        "    \"\"\"\n",
        "    db_folder = \"chroma_db\"\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "    print(f\"db_path = {db_path}\")\n",
        "    chroma_client = setup_chroma_db(db_path)\n",
        "\n",
        "    # Assuming embeddings and text chunks have already been added without specifying a file\n",
        "    relevant_chunks, relevant_metadata = retrieve_relevant_chunks_with_metadata(chroma_client, query)\n",
        "\n",
        "    if not relevant_chunks:\n",
        "        return \"No relevant information found in the document for the query.\"\n",
        "\n",
        "    rag_response = generate_response_with_gemini(query, relevant_chunks)\n",
        "    return rag_response\n",
        "\n",
        "# Main function to orchestrate RAG process\n",
        "def perform_rag(file_path, query):\n",
        "    \"\"\"Orchestrates the RAG process.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the text file in Google Colab.\n",
        "        query: User query string.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response based on RAG.\n",
        "    \"\"\"\n",
        "    text_content = load_text_file(file_path)\n",
        "    if not text_content:\n",
        "        return \"Error: Could not load text file. Please check the file path.\"\n",
        "\n",
        "    text_chunks = chunk_text(text_content)\n",
        "    if not text_chunks: # Handle the case where chunking fails\n",
        "      return \"Error: Could not chunk the text content.\"\n",
        "    embeddings_response = embed_text_with_gemini(text_chunks)\n",
        "    if not embeddings_response: #Handles case where embedding fails\n",
        "        return \"Error: Could not embed the text chunks\"\n",
        "\n",
        "    db_folder = \"chroma_db\"\n",
        "    # db_name = \"rag_experiment\"\n",
        "    db_path = os.path.join(os.getcwd(), db_folder)\n",
        "    chroma_client = setup_chroma_db(db_path)\n",
        "    chroma_collection = add_to_chroma_db_with_metadata(chroma_client, embeddings_response, text_chunks)\n",
        "\n",
        "    relevant_chunks = retrieve_relevant_chunks_with_metadata(chroma_client, query)\n",
        "    if not relevant_chunks:\n",
        "        return \"No relevant information found in the document for the query.\"\n",
        "\n",
        "    rag_response = generate_response_with_gemini(query, relevant_chunks)\n",
        "    return rag_response\n",
        "\n",
        "# --- Example Usage in Google Colab ---\n",
        "\n",
        "# 1. Upload your text file to Google Colab.\n",
        "#    - You can use the file upload button in the Colab sidebar (Files tab).\n",
        "#    - Let's assume your file is named 'my_text_file.txt' and is in the root directory of your Colab environment.\n",
        "\n",
        "### Example files:\n",
        "#file_path = 'wishing-info.txt'  # Replace with your file name if different\n",
        "file_path = 'formatted_weapon_data.txt'  # Replace with your file name if different\n",
        "#file_path = 'formatted_character_data.txt'  # Replace with your file name if different\n",
        "user_query = \"What is the main topic of this document?\" # Replace with your query\n",
        "#user_query = \"Which weapons have Energy Recharge as a substat?\"\n",
        "\n",
        "# Perform RAG and get the response\n",
        "#output_response = perform_rag(file_path, user_query)\n",
        "\n",
        "# Print the response\n",
        "#print(\"Query:\", user_query)\n",
        "#print(\"RAG Response:\", output_response)\n",
        "\n",
        "### Test embedding and storing file only without query:\n",
        "#file_path = 'formatted_weapon_data.txt'\n",
        "#file_path = 'formatted_character_data.txt'\n",
        "file_path = 'wishing-info.txt'\n",
        "result = store_embeddings_from_file(file_path)\n",
        "print(result)\n",
        "\n",
        "## Test querying after file is stored first:\n",
        "preform_rag_with_query(\"What is base rate I roll a 5 star with no pity?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== FastAPI 包裝 RAG API =====\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    response: str\n",
        "\n",
        "@app.post(\"/api/rag-query\", response_model=QueryResponse)\n",
        "def rag_query(request: QueryRequest):\n",
        "    query = request.query\n",
        "    rag_response = perform_rag(query)\n",
        "    return QueryResponse(response=rag_response)"
      ],
      "metadata": {
        "id": "K8uyOweK9K2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TavilySearch**"
      ],
      "metadata": {
        "id": "D06FRWkaoorz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB364YHVgQfx",
        "outputId": "5247764f-b3c5-4b59-c2d8-43f9aeeac7d0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tavily-python\n",
        "from google.colab import userdata  # For Colab secrets\n",
        "from tavily import TavilyClient\n",
        "\n",
        "@app.post(\"/api/tavily-search\")\n",
        "def tavily_search(query, search_depth=\"basic\", time_range=None, include_answer=None, max_results=5, include_domains=None):\n",
        "    \"\"\"\n",
        "    Overlay function for Tavily API search.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The search query. necessary\n",
        "        search_depth (str): \"basic\" or \"advanced\".\n",
        "        time_range (str or None): Time filter, e.g., \"d\" (day), \"w\" (week), \"m\" (month), \"y\" (year).\n",
        "        include_answer (str): \"none\", \"basic\", or \"advanced\".\n",
        "        max_results (int): Number of results to return.\n",
        "        include_domains (list or None): List of domains to include (default is None).\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        dict: Search results from Tavily API.\n",
        "    \"\"\"\n",
        "\n",
        "   # tavily_client = TavilyClient(userdata.get('TAVILY_API_KEY'))\n",
        "    tavily_client = TavilyClient(\"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\")\n",
        "    search_params = {\n",
        "      \"query\": query,\n",
        "      \"search_depth\": search_depth,\n",
        "      \"max_results\": max_results,\n",
        "    }\n",
        "\n",
        "    if time_range in [\"y\", \"m\", \"w\", \"d\"]:\n",
        "        search_params[\"time_range\"] = time_range\n",
        "    if include_answer in [\"basic\", \"advanced\"]:  # 只允許 Tavily API 支援的值\n",
        "        search_params[\"include_answer\"] = include_answer\n",
        "    if include_domains:\n",
        "        search_params[\"include_domains\"] = include_domains\n",
        "\n",
        "    response = tavily_client.search(**search_params)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooP2j8SGkfSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9c3646-4fa3-4b2b-d5de-b72cef536dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Latest AI news', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Latest AI News: February 24, 2025 - OpenTools', 'url': 'https://opentools.ai/news', 'content': \"Latest AI News: Daily Updated Artificial Intelligence Insights (February 7, 2025) Learn to use AI like a Pro. Learn More (And Unlock 50% off!) Latest AI News: February 7, 2025 AI Tools Researcher & Implementation Consultant SpaceX's $2.9 Billion NASA Contract for Artemis: A Dichotomy with DEI Reduction Goals NASA's Rebranding Sparks Debate: Email Pronouns Removed Under Trump's Executive Order In a move stirring controversy, NASA employees have been directed to remove pronouns from email sign... Discover the heated debate surrounding NASA's space exploration goals as Artemis contractors and off... AI Pioneers Extra-Terrestrial Terrain: NASA Tests Show Unprecedented Success Learn to use AI like a Pro New AI Tools Advertise with OpenTools Top AI Use Cases\", 'score': 0.8803145, 'raw_content': None}, {'title': 'Artificial Intelligence News - ScienceDaily', 'url': 'https://www.sciencedaily.com/news/computers_math/artificial_intelligence/', 'content': 'Jan. 15, 2025 — A new initiative is challenging the conversation around the direction of artificial intelligence (AI). Jan. 16, 2025 — Researchers have developed a novel 6D pose dataset designed to improve robotic grasping accuracy and adaptability in industrial settings. Dec. 19, 2024 — Researchers developed a laser-based artificial neuron that fully emulates the functions, dynamics and information processing of a biological graded neuron, which could lead to new breakthroughs in ... Dec. 9, 2024 — Imagine an artificial intelligence (AI) model that can watch and understand moving images with the subtlety of a human brain. Dec. 2, 2024 — A research team has taken inspiration from the brains of insects and animals for more energy-efficient robotic ...', 'score': 0.84918517, 'raw_content': None}, {'title': 'AI News | Latest AI News, Analysis & Events', 'url': 'https://www.artificialintelligence-news.com/', 'content': 'AI News is part of the TechForge Publications series Applications, Artificial Intelligence, Chatbots, Companies, Development, Legislation & Government, Privacy, Surveillance Artificial Intelligence, Data Center, Ethics & Society, Legislation & Government AGI, Applications, Artificial Intelligence, Chatbots, Companies Artificial Intelligence, Chatbots, Companies, Development AGI, Applications, Artificial Intelligence, Chatbots, Companies AGI, Applications, Artificial Intelligence, cloud, Companies, Data Center, Security AGI, Artificial Intelligence, Companies, Development AGI, Applications, Artificial Intelligence, Chatbots, Companies, Development, Ethics & Society, Virtual Assistants Applications, Artificial Intelligence, Chatbots, Companies, Development, Legislation & Government, Privacy, Surveillance Applications, Artificial Intelligence, Chatbots, Companies, Development, Legislation & Government, Privacy, Surveillance AGI, Applications, Artificial Intelligence, Chatbots, Companies Artificial Intelligence, Development, Ethics & Society, Legislation & Government, Machine Learning, Privacy AI News AI News AI News AI News is part of TechForge\\xa0', 'score': 0.8127637, 'raw_content': None}, {'title': 'Artificial intelligence | AP News', 'url': 'https://apnews.com/hub/artificial-intelligence', 'content': 'Food & Recipes Gardening Homes Travel Fashion Pets Food & Recipes Gardening Homes Travel Fashion Pets (AP Photo/Matt Rourke, file)](https://dims.apnews.com/dims4/default/3e31970/2147483647/strip/true/crop/6000x4000+0+0/resize/567x378!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F77%2Fed%2Fca768a708f9c4dbb31d8462c3138%2Fdd455c2b9b2849ddb719c12af50dc6a4)](https://apnews.com/article/amazon-earnings-fourth-quarter-ai-bac8e33542ee7eae02dddd68a33bf189) (AP Photo/Andy Wong, File)](https://dims.apnews.com/dims4/default/b96e7be/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0f%2Fe0%2Feebd5306d9f926701c8eebf22d3e%2F207128d6594c43af9013790325825b82)](https://apnews.com/article/deepseek-ai-china-us-ban-6fea0eb28735b9be7f4592185be5f681) (AP Photo/Juliana Yamada, File)](https://dims.apnews.com/dims4/default/c9e28c2/2147483647/strip/true/crop/5322x3545+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fa4%2F27%2Fe89ec92a6f7ed9523e081028a596%2Fc325c77816a147b19e36eebbdc5ed24b)](https://apnews.com/article/google-alphabet-quarterly-earnings-artificial-intelligence-57590db6f7db3b5aa5f4ab353e44a211) (AP Photo/Andy Manis, Susan Crawford for Wisconsin, File)](https://dims.apnews.com/dims4/default/0d20e1b/2147483647/strip/true/crop/3349x2231+0+85/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fc9%2Fa6%2F1b5e929938d8df2620fac34739e5%2F1e8aca3054f0438e925b1f28310034ba)](https://apnews.com/article/wisconsin-supreme-court-altered-image-a00dba9df6d011f4ad5b61c1fe6ec5c6) (AP Photo/Alex Brandon)](https://dims.apnews.com/dims4/default/d31ac46/2147483647/strip/true/crop/7037x4687+0+4/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0d%2F2e%2Fdb8ed9a51c748e6dbcf9a6d7e10a%2F1a548526ad6b487aa2cf34a0d9ddcf09)](https://apnews.com/article/vance-trip-paris-ai-summit-ea6ccd6b23e55776fcf081af74b2ddaa) (Kyodo News via AP)](https://dims.apnews.com/dims4/default/e4584f0/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fca%2F2d%2Fb7a7f3d4cafad12016257291e5fb%2F500adc2495b34624841e51c0a077ca09)](https://apnews.com/article/ai-softbank-openai-technology-7abf34541acc2d48bd58dff2a73d9e6f) (AP Photo/Andy Wong)](https://dims.apnews.com/dims4/default/2fb1b4f/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F83%2Fe9%2F5da0fa1c259f97af548dc083d8d6%2Fdd4f1d7982d44dd999262c91bda46668)](https://apnews.com/article/texas-deepseek-apps-ban-3828a4743e9919398dfac0ba9d4a5c25) (AP Photo/Evan Vucci)](https://dims.apnews.com/dims4/default/84a8c1c/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F49%2Fbd%2F9a2eb20e96047bb4ce9725fa34bd%2Fa36226fdbc484b0eb8383c9304f6bf93)](https://apnews.com/article/deepseek-nvidia-trump-ai-6554b843e94f2e86c2ea7ba7c180f8bf) (AP Photo/Andy Wong, File)](https://dims.apnews.com/dims4/default/b96e7be/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0f%2Fe0%2Feebd5306d9f926701c8eebf22d3e%2F207128d6594c43af9013790325825b82)](https://apnews.com/article/italy-blocks-deepseek-chatbot-artificial-intelligence-dc7e87835ed7a125b5e46614ddbd80d0) (AP Photo/Seth Wenig)](https://dims.apnews.com/dims4/default/8545568/2147483647/strip/true/crop/3447x2296+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F22%2F2a%2F5799fc982d2ceeaebe4d1adcbab6%2F3bc5aba63ffc422da039ab1b99c4b26e)](https://apnews.com/article/stock-markets-rates-earnings-trump-c28b59976826c2d8392873ee024af9b5) (AP Photo/Charles Rex Arbogast, File)](https://dims.apnews.com/dims4/default/30b083e/2147483647/strip/true/crop/4101x2732+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fd7%2Fe6%2F5b1f4a46b15da499807c17458579%2Fbf125c4f2a5d4674a08346580c3a777a)](https://apnews.com/article/microsoft-earnings-profit-ai-artificial-intelligence-1ce95c424d708b51f21873a5029c236e) Scott Applewhite, File)](https://dims.apnews.com/dims4/default/1388d23/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F72%2F4566fff25033af3e2cc3d3868038%2F663f8e75dd40444fb48a1bb45dfbecff)](https://apnews.com/article/ai-copyright-office-artificial-intelligence-363f1c537eb86b624bf5e81bed70d459) (AP Photo/Andy Wong)](https://dims.apnews.com/dims4/default/d4f954b/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F47%2F03%2F9494304de5a6dac146df2053b2b2%2F8bbb47bf976b48b5bc21beb210a8bdce)](https://apnews.com/article/deepseek-ai-chatgpt-openai-copyright-a94168f3b8caa51623ce1b75b5ffcc51) (AP Photo/Andy Wong)](https://dims.apnews.com/dims4/default/80bd97f/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F41%2F1e%2F46080a44a0f2643e0b699780606e%2Fa72982a7165f43c9b1592c1a86a2871c)](https://apnews.com/article/deepseek-ai-china-climate-fossil-fuels-00c594310b22afbf150559d08b43d3a5) (AP Photo/Jeff Chiu, File)](https://dims.apnews.com/dims4/default/af85f03/2147483647/strip/true/crop/3000x1998+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fc8%2Ffa%2F6456a46330d39f7952c6bf9777c2%2F897e90a116084ac6b940db09d8460f6f)](https://apnews.com/article/nvidia-stock-ai-deepseek-wall-street-5ef5329d2a864f7f733f7e8984366238) (AP Photo/Jeff Chiu, File)](https://dims.apnews.com/dims4/default/5851f9a/2147483647/strip/true/crop/4651x3098+429+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F47%2F97%2F48cf30331c0b45fe5feb606606af%2F4408894f37b3431b9d2e7a1e4e0a58b1)](https://apnews.com/article/chevron-trump-ge-vernova-ai-deepseek-86f56ec2bacef971e76a487ff0886074) (AP Photo/Andy Wong)](https://dims.apnews.com/dims4/default/2fb1b4f/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F83%2Fe9%2F5da0fa1c259f97af548dc083d8d6%2Fdd4f1d7982d44dd999262c91bda46668)](https://apnews.com/article/deepseek-founder-liang-wenfeng-china-ai-0673d5c39d90108189cc31b88d85b9f8) (AP Photo/Jon Elswick)](https://dims.apnews.com/dims4/default/60bd54f/2147483647/strip/true/crop/3578x2383+0+3/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F3d%2F5f%2F52d9e8990cc98329ae2443dd8dc9%2F53ba9cabd1044e558fe891be239ebecb)](https://apnews.com/article/china-ai-models-usa-technology-92d10dc20e3110b2774a5bc8f976e8f9) (AP Photo/Julia Demaree Nikhinson)](https://dims.apnews.com/dims4/default/974159a/2147483647/strip/true/crop/5680x3784+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F94%2Fad%2F21c0c91cada867bc6170fd350a80%2Fd2ccfa1eb8ed4b17993301ca3d02f38a)](https://apnews.com/article/stock-markets-technology-ai-rates-trump-99e7eabd9e71dfe8f3cd37d8afecdf77) (AP Photo/Seth Wenig)](https://dims.apnews.com/dims4/default/2ba2614/2147483647/strip/true/crop/4919x3277+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F29%2F18%2F1b6386b505bff4d7ad995b664e41%2F89ad898c6c5f4fb9b9d2646d1f901cc8)](https://apnews.com/article/deepseek-ai-markets-nvidia-tech-oracle-285eea9b1f1defa757ed1aebf5793dcc) (AP Photo/Markus Schreiber)](https://dims.apnews.com/dims4/default/3c6a4cc/2147483647/strip/true/crop/5982x3985+9+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Faf%2F9d%2Feec60df1bb34f7edab04f13f0345%2F555c1e0b0c674ac2a634bf2b48775a6e)](https://apnews.com/article/deepseek-ai-artificial-intelligence-be414acadbf35070d7645fe9fbd8f464) (AP Photo/Markus Schreiber)](https://dims.apnews.com/dims4/default/790b484/2147483647/strip/true/crop/8380x5582+12+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F3d%2F13%2F3567b7e98d698f1900f7dd722b1f%2Fd3bce37a2580412fa5a831ec7fd762f8)](https://apnews.com/article/deepseek-ai-china-f4908eaca221d601e31e7e3368778030) [![Image 30: (AP Illustration / Jenni Sohn)](https://dims.apnews.com/dims4/default/3d717f8/2147483647/strip/true/crop/1919x1278+1+0/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fc8%2Fef%2F6d7ce505a7a529c4385390494f1c%2F072bc92aa8a34b19bd54c91fb11d9a72)](https://apnews.com/article/reid-hoffman-linkedin-artificial-intelligence-trump-aa9600b3c82f886cbe336f519672f9d7) (AP Photo/Peter Morgan, File)](https://dims.apnews.com/dims4/default/f6f4e56/2147483647/strip/true/crop/3840x2558+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F81%2Ff3%2F59d52bcae772dce8698998abf3c7%2Fe4177ff6830943ae92a6881d22994309)](https://apnews.com/article/stocks-markets-tariffs-trump-rates-52c54e361616509280bd2775674b6b4b) (AP Photo/Ben Curtis)](https://dims.apnews.com/dims4/default/a71e813/2147483647/strip/true/crop/6139x4089+0+4/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F78%2F77%2F5c416a5e8d9aebeb4b4bf82608f9%2F7a80d63bc3894c7dbdd5eff346fa7b9e)](https://apnews.com/article/trump-ai-artificial-intelligence-executive-order-eef1e5b9bec861eaf9b36217d547929c) (Kevin Lamarque/Pool Photo via AP)](https://dims.apnews.com/dims4/default/35affae/2147483647/strip/true/crop/4109x2737+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fa3%2F51%2Fa711738e55796dd07c3554b69353%2F43329787d6e94d05ae319a4e26bff758)](https://apnews.com/article/stargate-ai-project-trump-musk-openai-sam-altman-oracle-softbank-734610c6dbe62a244527c6fd621fa004) (AP Photo/Evan Vucci)](https://dims.apnews.com/dims4/default/deef817/2147483647/strip/true/crop/5354x3566+0+4/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F8e%2F44%2F31d26e29a7ee1e3b922c0a43e0d1%2Faf6840a973d04bce80e376d1ed640ed1)](https://apnews.com/article/trump-ai-repeal-biden-executive-order-artificial-intelligence-18cb6e4ffd1ca87151d48c3a0e1ad7c1)', 'score': 0.7640656, 'raw_content': None}, {'title': 'Artificial Intelligence | Latest News, Photos & Videos | WIRED', 'url': 'https://www.wired.com/tag/artificial-intelligence/', 'content': 'Artificial Intelligence | Latest News, Photos & Videos | WIRED WIRED Classics from the Archive By Paresh Dave, Zoë Schiffer, and Makena Kelly ### LinkedIn Is Testing an AI Tool That Could Transform How People Search for Jobs ### OpenAI’s o3-Mini Is a Leaner AI Model That Keeps Pace With DeepSeek ### DeepSeek’s Safety Guardrails Failed Every Test Researchers Threw at Its AI Chatbot ### DeepSeek’s New AI Model Sparks Shock, Awe, and Questions From US Competitors ### DeepSeek’s Popular AI App Is Explicitly Sending US Data to China ### Chinese AI App DeepSeek Soars in Popularity, Startling Rivals ### How Chinese AI Startup DeepSeek Made a Model that Rivals OpenAI More From WIRED WIRED Staff Reviews and Guides', 'score': 0.7323053, 'raw_content': None}], 'response_time': 1.2}\n"
          ]
        }
      ],
      "source": [
        "# Test tavily_search\n",
        "result1 = tavily_search(\"Latest AI news\")\n",
        "print(result1)\n",
        "\n",
        "# result2 = tavily_search(\"Latest AI news\", include_domains=[\"reddit.com\"])\n",
        "# print(result2)\n",
        "\n",
        "# result3 = tavily_search(\"Future of AI\", time_range = \"d\", max_results=1, search_depth = \"basic\", include_answer = \"basic\", include_domains=[\"medium.com\", \"techcrunch.com\"])\n",
        "# print(result3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r86S7bb_7HtE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# for human reading\n",
        "def format_result_as_json(result):\n",
        "    formatted_result = {\n",
        "        \"query\": result[\"query\"],\n",
        "        \"follow_up_questions\": result[\"follow_up_questions\"],\n",
        "        \"answer\": result[\"answer\"],\n",
        "        \"images\": result[\"images\"],\n",
        "        \"results\": [\n",
        "            {\n",
        "                \"url\": item[\"url\"],\n",
        "                \"title\": item[\"title\"],\n",
        "                \"content\": item[\"content\"],\n",
        "                \"score\": item[\"score\"]\n",
        "            }\n",
        "            for item in result[\"results\"]\n",
        "        ],\n",
        "        \"response_time\": result[\"response_time\"]\n",
        "    }\n",
        "\n",
        "    json_output = json.dumps(formatted_result, ensure_ascii=False, indent=4)\n",
        "    return json_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXecrpEQ4sYm"
      },
      "source": [
        "---\n",
        "**Crawler on certain website [reddit.com]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wqJJt-UN7K4k",
        "outputId": "a192c03c-39c9-4574-83fb-72b55894128b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install praw requests beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"J51PzebYQY_vynvS7KUBOw\",\n",
        "    client_secret=\"Kwf1A10ku-7VDRksvtS74-w3gCyPoQ\",\n",
        "    user_agent=\"chatbot\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zXKv8r4rSOA",
        "outputId": "8e842130-fa3a-4c41-a333-88851e1ee100",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"query\": \"How to quickly earn money in Genshin?\",\n",
            "    \"follow_up_questions\": null,\n",
            "    \"answer\": null,\n",
            "    \"images\": [],\n",
            "    \"results\": [\n",
            "        {\n",
            "            \"url\": \"https://genshin-impact.fandom.com/wiki/Battle_Pass\",\n",
            "            \"title\": \"Battle Pass | Genshin Impact Wiki | Fandom\",\n",
            "            \"content\": \"The items' values in Original Resin are as follows: . 519 Original Resin for 159 Hero's Wit via Ley Line Outcrops at World Levels 6-9.; 540 Original Resin for 324 Mystic Enhancement Ore using Magical Crystal Chunk.. 10.8 Days, without using Original Resin, to use 1,296 Crystal Chunks to craft 324 Mystic Enhancement Ore.; 540 Original Resin for 1,620,000 Mora via Ley Line Outcrops at World\",\n",
            "            \"score\": 0.41606155\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://genshin-impact.fandom.com/wiki/Mora\",\n",
            "            \"title\": \"Mora - Genshin Impact Wiki\",\n",
            "            \"content\": \"Mora Mora Mora is the main currency unit used to purchase various items and upgrades in Genshin Impact. Mora ×1    Ekaterina  A Huge Bag of Mora ×1  50,000  — Mora ×1    Ekaterina  Childe and Teucer's Mora Pouch ×1  35,000  — Mora ×10,000   Khalid  2   20  — Mora ×3,000    Khalid  1   ∞   — Mora ×1,600    Marjorie    1   60  — Mora ×1,600    Marjorie    2   ∞   — Mora ×10,000   Mequignon   2   20  — Mora ×3,000    Mequignon   1   ∞   — Mora ×10,000   Mikoshi Genichirou  2   20  — Mora ×3,000    Mikoshi Genichirou  1   ∞   — Mora ×1,600    Xingxi  1   120 — Mora ×1,600    Xingxi  2   ∞   — English Mora Mora Mora Mora Genshin Impact Wiki is a FANDOM Games Community.\",\n",
            "            \"score\": 0.38810825\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://genshin-impact.fandom.com/wiki/Weekly_Boss\",\n",
            "            \"title\": \"Weekly Boss - Genshin Impact Wiki\",\n",
            "            \"content\": \"Weekly Bosses are bosses whose rewards can be claimed once per week. After defeating each boss, a Trounce Blossom will spawn where players can choose to spend Original Resin ×30 to claim the rewards from the first three weekly bosses of their choice, and then Original Resin ×60 subsequently. Availability of rewards and reduced resin costs reset at 4 AM server time every Monday. Weekly Bosses\",\n",
            "            \"score\": 0.36752048\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://genshin-impact.fandom.com/wiki/Adventurer_Handbook\",\n",
            "            \"title\": \"Adventurer Handbook | Genshin Impact Wiki | Fandom\",\n",
            "            \"content\": \"The Adventurer Handbook provides many useful features to players including: Offers rewards based on the player's progress. Select the preferred region for Commissions and track them for the day with rewards. Displays the Domains they currently have access to and their rewards. Displays and tracks the locations of Enemies and their possible drops. Recommended priority Quests to be completed\",\n",
            "            \"score\": 0.3564248\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://genshin-impact.fandom.com/wiki/Promotional_Code\",\n",
            "            \"title\": \"Promotional Code | Genshin Impact Wiki | Fandom\",\n",
            "            \"content\": \"Promotional Code | Genshin Impact Wiki | Fandom Characters Event Quests Events Character EXP Materials Character and Weapon Enhancement Materials Character Talent Materials Characters Event Quests Events Character EXP Materials Character and Weapon Enhancement Materials Character Talent Materials in: Events Promotional codes are occasionally released by HoYoverse as part of social media events, live streams, celebratory milestones, or similar activities. Online: Through the official Genshin Impact Code Redemption page. The player must be at least Adventure Rank 10 to redeem most of the codes. Current exceptions are GENSHINGIFT and codes claimed from the Prime Gaming offer, which are redeemable as early as Adventure Rank 1. Events Español 日本語 Türkçe Tiếng Việt 中文 Genshin Impact Wiki is a FANDOM Games Community.\",\n",
            "            \"score\": 0.3548806\n",
            "        }\n",
            "    ],\n",
            "    \"response_time\": 1.82\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "@app.post(\"/api/checkTargetWeb\")\n",
        "def checkTargetWeb(url):\n",
        "    \"\"\"\n",
        "    Check if the url is target url. If true, crawl the post title, content and top five comments.\n",
        "    Target url: reddit.com\n",
        "    \"\"\"\n",
        "    if \"reddit.com\" in url:\n",
        "        print(f\"It's a Reddit url: {url}\")\n",
        "        try:\n",
        "            post_id = url.split(\"/\")[-3]  # Get Reddit post ID\n",
        "            submission = reddit.submission(id=post_id)\n",
        "\n",
        "            title = submission.title.strip()\n",
        "            content = submission.selftext.strip()\n",
        "\n",
        "            # crawl top 5 comment\n",
        "            submission.comments.replace_more(limit=0)  # remove \"load more comments\"\n",
        "            comments = [comment.body.strip() for comment in submission.comments[:5]]\n",
        "\n",
        "            # convert to json\n",
        "            reddit_data = {\n",
        "                \"title\": title,\n",
        "                \"content\": content,\n",
        "                \"comments\": comments\n",
        "            }\n",
        "\n",
        "            print(reddit_data)\n",
        "\n",
        "            return reddit_data\n",
        "        except Exception as e:\n",
        "            print(f\"Can't crawl Reddit: {e}\")\n",
        "            return None\n",
        "    # TODO: genshin-impact.fandom.com\n",
        "    # else:\n",
        "\n",
        "\n",
        "result = tavily_search(\"How to quickly earn money in Genshin?\", include_domains=[\"reddit.com\", \"genshin-impact.fandom.com\"])\n",
        "print(format_result_as_json(result))\n",
        "for result_item in result['results']:\n",
        "    url = result_item['url']\n",
        "    checkTargetWeb(url)\n",
        "    # print(checkTargetWeb(url))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Gemini Chatbot**"
      ],
      "metadata": {
        "id": "kNxDEjEMoW5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gN9MFKJF5vrZ",
        "outputId": "7dcc4f77-22db-4ce0-d304-ef09707eb10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi I'm Paim0n, ready to assist you in the world of Teyvat!\n",
            "Current selected model:  gemini-1.5-flash\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-11:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 445, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 276, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x791256800410>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x791256800410>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1401, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x791256800410>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "# Configure the Gemini API\n",
        "#secret = userdata.get('GOOGLE_API_KEY')          ### extract API key from notebook secret\n",
        "# Google API Key setup\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCd8Xh2bygG4Ziux4hvMfbFuKs82hUYADA'\n",
        "\n",
        "\n",
        "# store conversation history\n",
        "conversation_history = []\n",
        "\n",
        "def get_embedding(text, model=\"models/embedding-001\"):\n",
        "    \"\"\"Generate an embedding vector for a given text.\"\"\"\n",
        "    response = genai.embed_content(model=model, task_type=\"semantic_similarity\", content=text)\n",
        "    return response.get([\"embedding\"], [])  # Returns the embedding vector\n",
        "\n",
        "    # Store conversation history\n",
        "    conversation_history = []\n",
        "\n",
        "def generate_response(user_input):\n",
        "    \"\"\"Generate a response using Gemini LLM with context-aware embeddings.\"\"\"\n",
        "    global conversation_history\n",
        "\n",
        "    conversation_history.append({\"role\": \"user\", \"parts\": user_input})\n",
        "\n",
        "    # Use the Gemini model to generate a response\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = genai.chat(messages=conversation_history).text\n",
        "\n",
        "    # Add AI response to history\n",
        "    bot_response = response.text\n",
        "    conversation_history.append({\"role\": \"user\", \"parts\": bot_response})\n",
        "\n",
        "    return bot_response\n",
        "\n",
        "\"\"\"\n",
        "# Show available models for content generation:\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"All Gemini Models available for content generation: \")\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "print(\"----------------------------------------------------\")\n",
        "\"\"\"\n",
        "\n",
        "# Initialize chat session\n",
        "selected_model = 'gemini-1.5-flash'\n",
        "model = genai.GenerativeModel(selected_model)\n",
        "system_message = (\n",
        "    \"You are Paim0n, an AI guide specialized in assisting players with the video game Genshin Impact, developed by HoYoverse. \"\n",
        "    \"Your role is to provide accurate and up-to-date information on all aspects of the game, including characters, builds, artifacts, weapons, \"\n",
        "    \"team compositions, game mechanics, event guides, exploration tips, and lore discussions. \"\n",
        "\n",
        "    \"You also help players complete quests by providing step-by-step guidance, puzzle solutions, and strategies for difficult encounters. \"\n",
        "    \"Additionally, you assist with finding rare items by providing detailed locations, farming routes, estimated respawn times, and the best methods to obtain them efficiently. \"\n",
        "    \"If players are looking for a specific area or an unfamiliar location, you offer navigation assistance, waypoints, and travel tips to help them reach their destination easily. \"\n",
        "\n",
        "    \"You should stay within the context of Genshin Impact and avoid answering unrelated questions. \"\n",
        "    \"If asked about leaks or unofficial content, politely inform the user that you only provide officially released information. \"\n",
        "    \"Maintain an energetic and friendly tone, just like the real Paimon, but avoid excessive repetition or filler phrases. \"\n",
        "\n",
        "    \"Your goal is to be the ultimate Genshin Impact companion, helping players optimize their experience, whether they need battle strategies, exploration guidance, \"\n",
        "    \"or tips on maximizing their resources efficiently.\"\n",
        ")\n",
        "# chat = model.start_chat(history=[{\"role\": \"system\", \"parts\": system_message}])\n",
        "# start chat\n",
        "chat = model.start_chat(history=[])\n",
        "# send system message as the first message and wait for completion\n",
        "response = chat.send_message(system_message)\n",
        "if response:  # ensure system message is processed before continuing\n",
        "  print(\"Hi I'm Paim0n, ready to assist you in the world of Teyvat!\")\n",
        "else:\n",
        "  print(\"System message not passed\")\n",
        "\n",
        "# Verify chosen model\n",
        "for m in genai.list_models():\n",
        "  model_name = m.name.split(\"/\")[-1]\n",
        "  if model_name == selected_model:\n",
        "    # print(\"----------------------------------------------------\")\n",
        "    print(\"Current selected model: \", model_name)\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# Run chatbot\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat_api():\n",
        "    data = request.get_json()\n",
        "    user_input = data.get(\"message\", \"\")\n",
        "\n",
        "    if not user_input:\n",
        "        return jsonify({\"error\": \"No input provided\"}), 400\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        # print(\"Paim0n: Goodbye Traveler! \")\n",
        "        return jsonify({\"reply\": \"Paim0n: Goodbye Traveler!\"})\n",
        "\n",
        "\n",
        "    # Generate response\n",
        "    # response = chat.send_message(user_input)\n",
        "    # Use tavily search\n",
        "    tavily_result = tavily_search(user_input)\n",
        "    # call RAG to search documents uploaded\n",
        "    rag_result = preform_rag_with_query(user_input)\n",
        "    query = f\"\"\"\n",
        "    Below is some external information from web search about the question:\n",
        "    {tavily_result}\n",
        "\n",
        "    Below is some external information from documents uploaded for context:\n",
        "    {rag_result}\n",
        "\n",
        "    Use Gemini LLM with context-aware embeddings and external information and internal information to provide a detailed and accurate answer to the query:\n",
        "    \"{user_input}\"\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    response = chat.send_message(query)\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "          print(\"Paim0n: \", chunk.text)\n",
        "    print(bot_reply)\n",
        "\n",
        "    # 回傳 JSON\n",
        "    return jsonify({\"reply\": bot_reply})\n",
        "\n",
        "    # 啟動 Flask\n",
        "app.run()\n",
        "# what is the optimal weapon for chongyun?\n",
        "# What are the build recommended for amber\n",
        "#"
      ]
    }
  ]
}